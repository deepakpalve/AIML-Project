{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIAYbYajk1w9"
   },
   "source": [
    "# Recurrent Neural Networks\n",
    "- Vanilla RNN\n",
    "- Gated Recurrent Units\n",
    "- Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1544646625339,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "8yy37hEYOEiQ",
    "outputId": "2d1d0d0a-874a-4e70-bc06-02e695726b41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0+cu113'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyv2Sy5WO8lK"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoCXfOh1RQun"
   },
   "source": [
    "## 1. Vanilla RNN\n",
    "![vanilla_RNN](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
    "\n",
    "\n",
    "- Vanilla RNN can be implemented with ```torch.nn.RNN()``` \n",
    "\n",
    "- Key Parameters\n",
    "  - ```input_size```:  number of expected features in the input (i.e., dimensionality of feature space)\n",
    "  - ```hidden_size```: number of features in hidden state (i.e., dimensionality of output space)\n",
    "  - ```num_layers```: number of recurrent layers (to create stacked RNN)\n",
    "  - ```batch_first```: If ```True```, input and output tensor shapes are ```(batch_size, seq_length, dim_feature)```. If ```False```, ```(sequence_length, batch_size, dim_feature)```\n",
    "  - ```bidirectional```: If ```True```, bidirectional RNN\n",
    "  \n",
    "- One thing to note is that unlike fully-connected layers or convolutional layers, RNNs take multi inputs/outputs\n",
    "  - In addition to (sequential) inputs, RNN has another called hidden state, which makes RNN special\n",
    "  - This hidden state sends information regarding current step to the next\\\n",
    "  \n",
    "- Inputs to RNN: ```(x0, h0)```\n",
    "  - ```x0```: tensor that contains features of the input sequence\n",
    "    - shape\n",
    "      - ```(seq_len, batch_size, input_size)``` if ```batch_first == False``` (default)\n",
    "      - ```(batch_size, seq_len, input_size)``` if ```batch_fist == True``` \n",
    "  - ```h0```: tensor that contains hidden state for each instance\n",
    "    - shape\n",
    "      - ```(num_layers * num_directions, batch_size, hidden_size)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kp_YDg0aQQ0e"
   },
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size = 10, \n",
    "             hidden_size = 5, \n",
    "             num_layers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1544646557492,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "rtVnd-SJomFA",
    "outputId": "4e2aaebc-fe5a-4946-b082-a84390d38312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 10]) torch.Size([1, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "## inputs to RNN\n",
    "# input data (seq_len, batch_size, input_size)\n",
    "x0 = torch.from_numpy(np.random.randn(12, 64, 10)).float()     \n",
    "# hidden state (num_layers * num_directions, batch_size, hidden_size)\n",
    "h0 = torch.from_numpy(np.zeros((1, 64, 5))).float()            \n",
    "\n",
    "print(x0.shape, h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1503,
     "status": "ok",
     "timestamp": 1544647163096,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "fDyuMNs9oyQ-",
    "outputId": "398e326a-c805-4c69-bd13-2d894224100d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 5]) torch.Size([1, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "## outputs from RNN\n",
    "# output (seq_len, batch_size, num_directions * hidden_size)\n",
    "# hidden state (num_layers * num_directions, batch_size, hidden_size)\n",
    "out, h1 = rnn(x0, h0)\n",
    "\n",
    "print(out.shape, h1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMcGMyJNSzSA"
   },
   "outputs": [],
   "source": [
    "# when batch_first = True\n",
    "rnn = nn.RNN(input_size = 10, \n",
    "             hidden_size = 5, \n",
    "             num_layers = 2,     # stacked RNN (2 layers)\n",
    "             batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1544647225067,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "1wKPW7qiWZJt",
    "outputId": "a84dc940-c6ee-4e42-a195-a781f6c1971b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 10]) torch.Size([2, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "## inputs to RNN\n",
    "x0 = torch.from_numpy(np.random.randn(64, 12, 10)).float()     \n",
    "# note that even batch_first == True, hidden state shape order does not change\n",
    "h0 = torch.from_numpy(np.zeros((2, 64, 5))).float()            \n",
    "\n",
    "print(x0.shape, h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1544647249382,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "aqUXKwvIXUH-",
    "outputId": "81931e92-f228-4de7-ea64-50eb37f16ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 5]) torch.Size([2, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "## outputs from RNN\n",
    "out, h1 = rnn(x0, h0)\n",
    "\n",
    "print(out.shape, h1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1544647257247,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "E4AJ3I9JWnyZ",
    "outputId": "952ac553-5608-4888-eafd-ccef2d44dfe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 20]) torch.Size([8, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "# bidirectional, stacked RNN\n",
    "rnn = nn.RNN(input_size = 20, \n",
    "             hidden_size = 10, \n",
    "             num_layers = 4,     \n",
    "             bidirectional = True)\n",
    "\n",
    "x0 = torch.from_numpy(np.random.randn(5, 64, 20)).float()\n",
    "h0 = torch.from_numpy(np.zeros((4 * 2, 64, 10))).float()  # notice the dimensionality of hidden state\n",
    "out, h1 = rnn(x0, h0)\n",
    "\n",
    "print(out.shape, h1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jJnvcgAXpSq"
   },
   "source": [
    "## 2. Gated Recurrent Units (GRU)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Gated_Recurrent_Unit%2C_base_type.svg/780px-Gated_Recurrent_Unit%2C_base_type.svg.png)\n",
    "\n",
    "- GRU has rather complicated structure compared to vanilla RNN (see below figure), but in terms of implementing it with Pytorch, largely similar to RNN, using ```torch.nn.GRU```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Irn1yF5lb3HO"
   },
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size = 10, \n",
    "             hidden_size = 5, \n",
    "             num_layers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1663,
     "status": "ok",
     "timestamp": 1544640247042,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "ddO_D_L2b81J",
    "outputId": "ec9c2336-aace-441d-9acb-42506c482c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 10]) torch.Size([1, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "## inputs to GRU\n",
    "# input data (seq_len, batch_size, input_size)\n",
    "x0 = torch.from_numpy(np.random.randn(12, 64, 10)).float()     \n",
    "# hidden state (num_layers * num_directions, batch_size, hidden_size)\n",
    "h0 = torch.from_numpy(np.zeros((1, 64, 5))).float()            \n",
    "\n",
    "print(x0.shape, h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1544640247498,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "ukQSVR0yY2VC",
    "outputId": "b98de175-9c9a-4297-ab94-e7808a25f1da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 5]) torch.Size([1, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "## outputs from GRU\n",
    "# output (seq_len, batch_size, num_directions * hidden_size)\n",
    "# hidden state (num_layers * num_directions, batch_size, hidden_size)\n",
    "out, h1 = gru(x0, h0)\n",
    "\n",
    "print(out.shape, h1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaM0ruFEtlQA"
   },
   "source": [
    "## 3. Long Short Term Memory (LSTM)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1200px-The_LSTM_cell.png)\n",
    "\n",
    "- LSTM is another variant of vanilla RNN that is widely used. Though there exist some differences in structure, when implementing one just need to attend to the cell state (c_t)\n",
    "  - Inputs to LSTM: (x0, (h0, c0)\n",
    "    - ```x0```: tensor that contains features of the input sequence\n",
    "      - shape: ```(seq_len, batch_size, input_size)```\n",
    "    - ```h0```: tensor that contains initial hidden state\n",
    "      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```\n",
    "    - ```c0```: tensor that contains initial cell state\n",
    "      - shape: ```(num_layers * num_directions, batch_size, hidden_size)``` (same as h0)\n",
    "  - Outputs to LSTM: (xn, (hn, cn))\n",
    "    - ```xn```: tensor that contains output features from the last layer\n",
    "      - shape: ```(seq_len, batch_size, num_directions * hidden_size)```\n",
    "    - ```hn```: tensor containing the hidden state\n",
    "      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```\n",
    "    - ```cn```: tensor containing the cell state\n",
    "      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSUeaLXatsK-"
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size = 10, \n",
    "             hidden_size = 5, \n",
    "             num_layers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1544647697084,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "uOcAQRqSt826",
    "outputId": "3bd8e411-0d5b-4ad1-9da5-daa7ba78a139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "## inputs to LSTM\n",
    "# input data (seq_len, batch_size, input_size)\n",
    "x0 = torch.from_numpy(np.random.randn(1, 64, 10)).float()     \n",
    "\n",
    "print(x0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1544647738377,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "iVEKLB3xLWAR",
    "outputId": "00d14088-7077-4262-a068-832ad811493b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 5])\n",
      "torch.Size([1, 64, 5]) torch.Size([1, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "# outputs from LSTM\n",
    "# when initial hidden & cell state are not given, they are regarded as zero\n",
    "xn, (hn, cn) = lstm(x0)\n",
    "\n",
    "print(xn.shape)               # (seq_len, batch_size, hidden_size)\n",
    "print(hn.shape, cn.shape)     # (num_layers, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1511,
     "status": "ok",
     "timestamp": 1544647909318,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "uNiSC9sPLf_w",
    "outputId": "1c8c0dc3-0892-44fe-ab7d-f625ac51d393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 5])\n",
      "torch.Size([1, 64, 5]) torch.Size([1, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "# when initial hidden & cell states are given\n",
    "x0 = torch.from_numpy(np.random.randn(1, 64, 10)).float()     \n",
    "h0, c0 = torch.from_numpy(np.zeros((1, 64, 5))).float(), torch.from_numpy(np.zeros((1, 64, 5))).float()\n",
    "\n",
    "xn, (hn, cn) = lstm(x0, (h0, c0))\n",
    "\n",
    "print(xn.shape)               # (seq_len, batch_size, hidden_size)\n",
    "print(hn.shape, cn.shape)     # (num_layers, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uiNzfCkuhHu"
   },
   "outputs": [],
   "source": [
    "# stacked, bidirectional LSTM\n",
    "lstm = nn.LSTM(input_size = 10, \n",
    "             hidden_size = 5, \n",
    "             num_layers = 2,\n",
    "             bidirectional = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1543,
     "status": "ok",
     "timestamp": 1544648053540,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "3SLQllzOMhEN",
    "outputId": "20d4d277-e0d0-42aa-c9bb-d3b1fdc6c9e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 10])\n",
      "torch.Size([4, 64, 5]) torch.Size([4, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "# inputs to LSTM\n",
    "x0 = torch.from_numpy(np.random.randn(5, 64, 10)).float()\n",
    "h0, c0 = torch.from_numpy(np.zeros((4, 64, 5))).float(), torch.from_numpy(np.zeros((4, 64, 5))).float()\n",
    "\n",
    "xn, (hn, cn) = lstm(x0, (h0, c0))\n",
    "\n",
    "print(xn.shape)\n",
    "print(hn.shape, cn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch-model-basics-4 [RNN].ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
